{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"stylegan-geometrictoolkit.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1W3Hq-waFJU5"},"source":["\n","\n","```\n","# This is formatted as code\n","```\n","\n","# Style-GAN generator\n","\n","Loads a pretrained Style-GAN2 generator in pytorch so that we can run tests for the geometric toolkit project.\n","\n","This code is based on https://github.com/rosinality/stylegan2-pytorch and also the ILO code of Daras et al."]},{"cell_type":"code","metadata":{"id":"K-NmUiSDFDOw"},"source":["#@title Run this cell to setup the repository (ignore the albumentations error)\n","# !git clone https://github.com/giannisdaras/ilo.git\n","# !mkdir ilo/files/inpainting\n","# !mkdir ilo/files/inversion\n","# !mkdir ilo/files/denoising\n","# !mkdir ilo/files/cls\n","!mkdir sample\n","!wget https://raw.githubusercontent.com/giannisdaras/ilo/f715ab73e8f62c7a9b1063cc133f0a1cdad093aa/requirements.txt\n","!pip install -r requirements.txt\n","# !wget https://zenodo.org/record/4536928/files/shape_predictor_68_face_landmarks.dat\n","!wget https://zenodo.org/record/4536928/files/stylegan2-ffhq-config-f.pt\n","# !mv stylegan2-ffhq-config-f.pt ilo/\n","from google.colab.patches import cv2_imshow\n","import cv2\n","import ipywidgets as widgets\n","import glob\n","import matplotlib.pyplot as plt\n","from ipywidgets import Layout\n","from PIL import Image\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z70MIG9EOzg3"},"source":["!git clone https://github.com/rosinality/stylegan2-pytorch.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kGf-iaB6dspe"},"source":["# Basic utilities: loading Obama, showing images, etc..."]},{"cell_type":"code","metadata":{"id":"xwmgPmLfSZFO"},"source":["from torchvision import utils\n","import torch\n","def show_img(currx):\n","  utils.save_image(\n","    currx,\n","    f\"test.png\",\n","    nrow=1,\n","    normalize=True,\n","    range=(-1, 1),\n","  )\n","  plt.imshow(cv2.imread('test.png')[:, :, ::-1])\n","  plt.show()\n","!wget https://pbs.twimg.com/media/EbCVjq6XYAEYr6Z.jpg\n","!mv EbCVjq6XYAEYr6Z.jpg obama.jpg\n","def load_obama():\n","  im = cv2.imread(\"obama.jpg\")\n","  im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","  im = np.swapaxes(im,1,2)\n","  im = np.swapaxes(im,0,1)\n","  im = torch.from_numpy(im)\n","  im = torch.unsqueeze(im,0)\n","  im = im.float()\n","  im = 2 * im / 255\n","  im = im - 1\n","  return im\n","show_img(load_obama())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4WRQL8dGFILU"},"source":["## Generate and show random images"]},{"cell_type":"code","metadata":{"id":"WMMfiCegLad3"},"source":["# This code loads the generator. It may take a couple of minutes to run.\n","import sys\n","sys.path.append('stylegan2-pytorch')\n","sys.argv = ['-f']\n","from model import Generator\n","import torch\n","import numpy as np\n","import argparse\n","from torchvision import utils\n","from generate import generate\n","# Code to load the generator is essentially taken from the code of https://github.com/rosinality/stylegan2-pytorch/blob/master/generate.py\n","\n","device = \"cuda\"\n","\n","parser = argparse.ArgumentParser(description=\"Generate samples from the generator\")\n","\n","parser.add_argument(\n","    \"--size\", type=int, default=1024, help=\"output image size of the generator\"\n",")\n","parser.add_argument(\n","    \"--sample\",\n","    type=int,\n","    default=1,\n","    help=\"number of samples to be generated for each image\",\n",")\n","parser.add_argument(\n","    \"--pics\", type=int, default=20, help=\"number of images to be generated\"\n",")\n","parser.add_argument(\"--truncation\", type=float, default=1, help=\"truncation ratio\")\n","parser.add_argument(\n","    \"--truncation_mean\",\n","    type=int,\n","    default=4096,\n","    help=\"number of vectors to calculate mean for the truncation\",\n",")\n","parser.add_argument(\n","    \"--ckpt\",\n","    type=str,\n","    default=\"stylegan2-ffhq-config-f.pt\",\n","    help=\"path to the model checkpoint\",\n",")\n","parser.add_argument(\n","    \"--channel_multiplier\",\n","    type=int,\n","    default=2,\n","    help=\"channel multiplier of the generator. config-f = 2, else = 1\",\n",")\n","\n","args = parser.parse_args()\n","\n","args.latent = 512\n","args.n_mlp = 8\n","\n","g_ema = Generator(\n","    args.size, args.latent, args.n_mlp, channel_multiplier=args.channel_multiplier\n",").to(device)\n","checkpoint = torch.load(args.ckpt)\n","\n","g_ema.load_state_dict(checkpoint[\"g_ema\"])\n","\n","if args.truncation < 1:\n","    with torch.no_grad():\n","        mean_latent = g_ema.mean_latent(args.truncation_mean)\n","else:\n","    mean_latent = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60YH_Okh7iJK"},"source":["def model_decode(model, latent, is_z=True):\n","  return model([latent], truncation=args.truncation, truncation_latent=mean_latent, input_is_latent=~is_z)[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S0QIk_LHA3n8"},"source":["import torch.optim as optim\n","\n","def get_graddir(model, z0,z1):\n","  x1 = model_decode(g_ema, z1).detach()\n","  optimizer = optim.Adam([z0], lr=0.001)\n","  z0.requires_grad = True\n","  x0 = model_decode(g_ema, z0)\n","  loss = torch.mean((x0 - x1)**2)\n","  loss.backward()\n","  grad_ret = torch.clone(z0.grad.detach())\n","  g_ema.zero_grad()\n","  return grad_ret"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"reDgLIGGBYtk"},"source":["## Histogram of dot products of nabla (g(z) - g(z1))^2|_{z = z0} for random z0, z1\n","latent_d = args.latent\n","numtrials = 1\n","dotprods = []\n","for i in range(100):\n","  print(i)\n","  z0 = torch.randn([numtrials, latent_d]).to(device)\n","  z1 = torch.randn([numtrials, latent_d]).to(device)\n","  graddir = get_graddir(g_ema, z0,z1)\n","  movedir = z1 - z0\n","  graddir = graddir / torch.norm(graddir)\n","  movedir = movedir / torch.norm(movedir)\n","  # print(graddir.shape)\n","  # print(movedir.shape)\n","  dotprods.extend([x for x in torch.sum(graddir * movedir,1).detach().cpu()])\n","plt.hist(np.asarray(dotprods))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_YYlQ_AgIfBB"},"source":["import torch.optim as optim\n","\n","def get_loss(model, z0,z1):\n","  x1 = model_decode(g_ema, z1).detach()\n","  optimizer = optim.Adam([z0], lr=0.001)\n","  z0.requires_grad = True\n","  x0 = model_decode(g_ema, z0).detach()\n","  with torch.no_grad():\n","    loss = torch.mean((x0 - x1)**2)\n","    return loss\n","\n","batch_size = 1\n","discretization = 50\n","dotprods = []\n","with torch.no_grad():\n","  for i in range(1):\n","    print(i)\n","    currlosses = []\n","    z0 = torch.randn([batch_size, latent_d]).to(device)\n","    z1 = torch.randn([batch_size, latent_d]).to(device)\n","    delta = z1 - z0\n","    for j in range(discretization):\n","      if j % 100 == 0:\n","        print(j)\n","      currz = z0 + delta * j / (discretization-1)\n","      currlosses.append(get_loss(g_ema,currz,z1))\n","    plt.plot(np.linspace(0,1,discretization),np.asarray(currlosses))\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_qvhHy_ZPeb0"},"source":["# Loss curve monotonicity during interpolation?\n","\n","import torch.optim as optim\n","import math\n","\n","def get_loss(model, z0,z1):\n","  x1 = model_decode(g_ema, z1).detach()\n","  optimizer = optim.Adam([z0], lr=0.01)\n","  z0.requires_grad = True\n","  x0 = model_decode(g_ema, z0).detach()\n","  with torch.no_grad():\n","    loss = torch.mean((x0 - x1)**2)\n","    return loss\n","\n","batch_size = 1\n","discretization = 50\n","dotprods = []\n","with torch.no_grad():\n","\n","  z1 = torch.randn([batch_size, latent_d]).to(device)\n","  for i in range(1):\n","    print(i)\n","    currlosses = []\n","    z0 = torch.randn([batch_size, latent_d]).to(device)\n","    delta = z1 - z0\n","    for j in range(discretization):\n","      t = j / (discretization-1)\n","      if j % 100 == 0:\n","        print(j)\n","      # currz = z0 * math.sqrt(1 - t**2) + z1 * t\n","      currz = z0 + t * delta\n","      currlosses.append(get_loss(g_ema,currz,z1))\n","    plt.plot(np.linspace(0,1,discretization),np.asarray(currlosses))\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLZI7jcG6qdg"},"source":["# Interpolating between two random images\n","\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import math\n","\n","numtrials = 1\n","for trialnum in range(numtrials):\n","  latent_d = args.latent\n","  numsteps = 10000\n","  learning_rate = 0.0001\n","  z0 = torch.randn([numtrials, latent_d]).to(device)\n","  # z1 = torch.randn([numtrials, latent_d]).to(device)\n","  z1 = z0 * math.sqrt(0) + torch.randn([numtrials, latent_d]).to(device) * math.sqrt(1)\n","\n","  ptlist = []\n","  currz = torch.clone(z0)\n","\n","  currz.requires_grad = True\n","  x1 = model_decode(g_ema, z1).detach() # g_ema is the name of the generator\n","  utils.save_image(\n","    x1,\n","    f\"test.png\",\n","    nrow=1,\n","    normalize=True,\n","    range=(-1, 1),\n","  )\n","  plt.imshow(cv2.imread('test.png')[:, :, ::-1])\n","  plt.show()\n","\n","  optimizer = optim.Adam([currz], lr=learning_rate)\n","  pt_list = []\n","  for step in range(numsteps):\n","    ptlist.append(torch.clone(currz))\n","    currx = model_decode(g_ema, currz)\n","    loss = torch.mean((currx - x1)**2)\n","    # if loss < 0.02:\n","    #   break\n","\n","    loss.backward()\n","    # print(currz.grad)\n","\n","    if step % 20 == 0:\n","\n","      with torch.no_grad():\n","        print('step',step)\n","        print('g(z1) - g(z)',loss)\n","        print('z0 - z',torch.mean((currz - z0)**2))\n","        print('z1 - z',torch.mean((currz - z1)**2))\n","      utils.save_image(\n","          currx,\n","          f\"test.png\",\n","          nrow=1,\n","          normalize=True,\n","          range=(-1, 1),\n","      )\n","      plt.imshow(cv2.imread('test.png')[:, :, ::-1])\n","      plt.show()\n","\n","    optimizer.step()\n","    optimizer.zero_grad()\n","  \n","    # with torch.no_grad():\n","    #   currz = currz * torch.norm(z1) / torch.norm(currz)\n","    # # print(torch.norm(currz.grad,dim=1))\n","    # # print(currz.grad)\n","    # with torch.no_grad():\n","    #   graddir = currz.grad / torch.norm(currz.grad, dim=1).view(numtrials, 1)\n","    #   currz.add_(-graddir, alpha=step_size)\n","\n","      # print(graddir)\n","\n","\n","    # z0grad = z0grad / torch.norm(z0grad,dim=1).view((numtrials,1))\n","    # print(currz)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6hMwfIHZvDpn"},"source":["torch.norm(z0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hCRQ4fwvFaY"},"source":["torch.norm(z1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RzPG_zwuvHWG"},"source":["delta = z1 - z0\n","deltac = currz - z0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X_3kOAWpvMzF"},"source":["deltau = delta / torch.norm(delta)\n","deltacu = deltac / torch.norm(deltac)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cd44UVRXvSec"},"source":["torch.sum(deltau * deltacu)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZefjA9lu8oi"},"source":["torch.norm(currz)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lQ2QI7Qmc3VH"},"source":["# Interpolating between two random images\n","\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import math\n","\n","numtrials = 1\n","for trialnum in range(numtrials):\n","  latent_d = args.latent\n","  numsteps = 100000\n","  learning_rate = 0.0001\n","  # z0 = torch.randn([numtrials, latent_d]).to(device)\n","  # # z1 = torch.randn([numtrials, latent_d]).to(device)\n","  # z1 = z0 * math.sqrt(0) + torch.randn([numtrials, latent_d]).to(device) * math.sqrt(1)\n","\n","  ptlist = []\n","  # currz = torch.clone(z0)\n","  currz = torch.clone(oldcurrz.detach())\n","\n","  currz.requires_grad = True\n","  x1 = model_decode(g_ema, z1).detach() # g_ema is the name of the generator\n","  utils.save_image(\n","    x1,\n","    f\"test.png\",\n","    nrow=1,\n","    normalize=True,\n","    range=(-1, 1),\n","  )\n","  plt.imshow(cv2.imread('test.png')[:, :, ::-1])\n","  plt.show()\n","\n","  optimizer = optim.Adam([currz], lr=learning_rate)\n","  pt_list = []\n","  for step in range(numsteps):\n","    ptlist.append(torch.clone(currz))\n","    currx = model_decode(g_ema, currz)\n","    loss = torch.mean((currx - x1)**2)\n","    # if loss < 0.02:\n","    #   break\n","\n","    loss.backward()\n","    # print(currz.grad)\n","\n","    if step % 20 == 0:\n","\n","      with torch.no_grad():\n","        print('step',step)\n","        print('g(z1) - g(z)',loss)\n","        print('z0 - z',torch.mean((currz - z0)**2))\n","        print('z1 - z',torch.mean((currz - z1)**2))\n","      utils.save_image(\n","          currx,\n","          f\"test.png\",\n","          nrow=1,\n","          normalize=True,\n","          range=(-1, 1),\n","      )\n","      plt.imshow(cv2.imread('test.png')[:, :, ::-1])\n","      plt.show()\n","\n","    optimizer.step()\n","    optimizer.zero_grad()\n","  \n","    # with torch.no_grad():\n","    #   currz = currz * torch.norm(z1) / torch.norm(currz)\n","    # # print(torch.norm(currz.grad,dim=1))\n","    # # print(currz.grad)\n","    # with torch.no_grad():\n","    #   graddir = currz.grad / torch.norm(currz.grad, dim=1).view(numtrials, 1)\n","    #   currz.add_(-graddir, alpha=step_size)\n","\n","      # print(graddir)\n","\n","\n","    # z0grad = z0grad / torch.norm(z0grad,dim=1).view((numtrials,1))\n","    # print(currz)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"muVrzRkedOdw"},"source":["oldcurrz = torch.clone(currz)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x7POQy_IEh1K"},"source":["def show_img(currx):\n","  utils.save_image(\n","    currx,\n","    f\"test.png\",\n","    nrow=1,\n","    normalize=True,\n","    range=(-1, 1),\n","  )\n","  plt.imshow(cv2.imread('test.png')[:, :, ::-1])\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"neo1i5ttEOTY"},"source":["import math\n","discretization = 10\n","with torch.no_grad():\n","  for i in range(discretization):\n","    t = i / ((discretization - 1))\n","    interpz = z0 * math.sqrt(1 - t**2) + z1 * t\n","    # interpz = currz * math.sqrt(1 - t**2) + z1 * t\n","    print(torch.mean((interpz - currz)**2))\n","    currx = model_decode(g_ema, interpz)\n","    show_img(currx)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qP08o0vEX0kH"},"source":["currz.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AFN2CQvGL_ru"},"source":["plt.hist(np.asarray(currz.detach().cpu()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xju0W8aAMFF_"},"source":["plt.hist(np.asarray(currz.detach().cpu()[0,:]),bins=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oXoGrf4eMNYy"},"source":["plt.hist(np.asarray(z0.detach().cpu()[0,:]),bins=50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C70Um74AMazB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5IMjFeLizJnv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VIwR5S9dzKha"},"source":["**George:** Use Langevin diffusion to sample the level sets of the generator function g(z) = c. Even though g(z) is a stochastic function (some layers have added noise) the variance of g(z) should still be small so studying its level sets should be fine."]},{"cell_type":"code","metadata":{"id":"IUp4aMWfzlr8"},"source":["# Interpolating between two random images\n","\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import math\n","\n","numtrials = 1\n","for trialnum in range(numtrials):\n","  latent_d = args.latent\n","  numsteps = 10000\n","  learning_rate = 0.0001\n","  z0 = torch.randn([numtrials, latent_d]).to(device)\n","  # z1 = torch.randn([numtrials, latent_d]).to(device)\n","  z1 = z0 * math.sqrt(0) + torch.randn([numtrials, latent_d]).to(device) * math.sqrt(1)\n","\n","  ptlist = []\n","  currz = torch.clone(z0)\n","\n","  currz.requires_grad = True\n","  x1 = model_decode(g_ema, z1).detach() # g_ema is the name of the generator\n","  utils.save_image(\n","    x1,\n","    f\"test.png\",\n","    nrow=1,\n","    normalize=True,\n","    range=(-1, 1),\n","  )\n","  plt.imshow(cv2.imread('test.png')[:, :, ::-1])\n","  plt.show()\n","\n","  optimizer = optim.Adam([currz], lr=learning_rate)\n","  pt_list = []\n","  for step in range(numsteps):\n","    ptlist.append(torch.clone(currz))\n","    currx = model_decode(g_ema, currz)\n","    loss = torch.mean((currx - x1)**2)\n","    # if loss < 0.02:\n","    #   break\n","\n","    loss.backward()\n","    # print(currz.grad)\n","\n","    if step % 20 == 0:\n","\n","      with torch.no_grad():\n","        print('step',step)\n","        print('g(z1) - g(z)',loss)\n","        print('z0 - z',torch.mean((currz - z0)**2))\n","        print('z1 - z',torch.mean((currz - z1)**2))\n","      utils.save_image(\n","          currx,\n","          f\"test.png\",\n","          nrow=1,\n","          normalize=True,\n","          range=(-1, 1),\n","      )\n","      plt.imshow(cv2.imread('test.png')[:, :, ::-1])\n","      plt.show()\n","\n","    optimizer.step()\n","    optimizer.zero_grad()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G8Va1uL3wJxb"},"source":["**George:** Study how well an epsilon box around randomly sampled z's in the latent space cover the space of [-1, 1]^{3x1024x1024} images."]},{"cell_type":"code","metadata":{"id":"dLP8_okqwy86"},"source":["latent_d = args.latent\n","print(latent_d)\n","\n","decode = lambda z : model_decode(g_ema, z).detach()\n","\n","def compute_jacobian(f, z, h=1e-5):\n","  fz = f(z).squeeze()\n","  z = z.squeeze()\n","  n = fz.size()\n","  d = z.size()\n","  J = torch.zeros(tuple(n) + tuple(d))\n","  #for i in range(d):\n","  #  zh = z.copy()\n","  #  zh[i] += h\n","  #  fzh = f(zh).squeeze()\n","  #  J[:, i] = (fzh - fz) / h\n","  \n","  return J\n","\n","# First study how isotropic the Gram matrices of the Jacobians are at random points.\n","# This should tell us if there are a few directions of large change in the output image.\n","trials = 100\n","conds = []\n","lmaxs = []\n","lmins = []\n","for i in range(trials):\n","  print(i)\n","  z = torch.randn([1, latent_d]).to(device)\n","  Jg = compute_jacobian(decode, z).view(-1, latent_d)\n","  G = torch.matmul(Jg.t(), Jg)\n","\n","  cond = torch.linalg.cond(G).item()\n","  lmax = torch.lobpcg(G)[0].item()\n","  lmin = torch.lobpcg(G, largest=False)[0].item()\n","\n","  conds.append(cond)\n","  lmaxs.append(lmax)\n","  lmins.append(lmin)\n","\n","#eps = 1e-6\n","#mean = torch.zeros([num_samples, latent_d]).to(device)\n","#zs = eps * (mean + torch.randn([num_samples, latent_d]).to(device) - 0.5)\n","#\n","#xs = model_decode(g_ema, zs).detach()\n","#\n","#\n","#print(xs.shape)\n","#x0 = xs[0, :, :, :]\n","#print(x0)\n","#utils.save_image(\n","#    x0,\n","#    f\"test.png\",\n","#    nrow=1,\n","#    normalize=True,\n","#    range=(-1, 1),\n","#  )\n","#plt.imshow(cv2.imread('test.png')[:, :, ::-1])\n","#plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ht413AVMuND"},"source":["y = torch.zeros((3, 1024, 1024, 512))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7pJ1pEk1iTX1"},"source":["f = lambda z : with torch.no_grad(): model_decode(g_ema, z).detach()\n","latent_d = args.latent\n","z = torch.randn([1, latent_d]).to(device)\n","fz = f(z).squeeze()\n","z = z.squeeze()\n","n = fz.size()\n","d = z.size()\n","print(tuple(n) + tuple(d))\n","J = np.zeros(tuple(n) + tuple(d))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cJvzCObacE_O"},"source":["## Sampling random standard Gaussian latent w generates monsters"]},{"cell_type":"code","metadata":{"id":"4AwFo4FLlK8T"},"source":["latent_d = args.latent\n","w = torch.randn([1, latent_d]).to(device)\n","x = model_decode(g_ema, w).detach()\n","\n","utils.save_image(\n","    x,\n","    f\"test.png\",\n","    nrow=1,\n","    normalize=True,\n","    range=(-1, 1),\n","  )\n","plt.imshow(cv2.imread('test.png')[:, :, ::-1])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yT1znL4ias3k"},"source":[""],"execution_count":null,"outputs":[]}]}