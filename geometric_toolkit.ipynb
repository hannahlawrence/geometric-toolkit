{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"geometric_toolkit.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"HHm1cOIx_2sz"},"source":["# Organization\n","\n","\n","1.   Training/loading VAE\n","2.   Computing geodesics on data manifold\n","3. Geodesics restricted to straight line\n","4. Derivative direction vs. interpolation direction\n","5. Greedy geodesics vs. straight-line geodesics\n","6. Studying the geodesics in more detail\n","\n"]},{"cell_type":"code","metadata":{"id":"uYvcEm6YBtRH"},"source":["import os\n","import argparse\n","import torch\n","import torch.utils.data\n","from torch import nn, optim\n","from torch.nn import functional as F\n","from torchvision import datasets, transforms\n","from torchvision.utils import save_image\n","import pickle\n","import sys\n","import numpy as np\n","import scipy\n","from scipy import stats\n","import matplotlib.pyplot as plt\n","import math\n","\n"," # To use the Google Colab GPU acceleration, go to Edit --> Notebook Settings.\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYElsJqABfjU"},"source":["\"\"\" The following code will store the trained models in your Google drive, so you\n","do not need to retrain the models every single time the notebook restarts.\n","\"\"\"\n","from google.colab import drive\n","drive.mount('/content/drive')\n","notebook_data_path = '/content/drive/MyDrive/geomtoolkit/'\n","if not os.path.exists(notebook_data_path):\n","  os.mkdir(notebook_data_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L8IqjEcR_RMK"},"source":["# Training/loading the VAE\n","\n","The following code either trains the VAE, or loads a pre-trained VAE from a pickle file. The latter is preferable if the VAE has not been yet trained."]},{"cell_type":"code","metadata":{"id":"aaRcZ5fgCcrz"},"source":["#@title Code: VAE class definition\n","\"\"\"\n","The following code is a slightly modified version of the pytorch library's\n","example directory for representing a simple VAE.\n","\"\"\"\n","class VAE(nn.Module):\n","    def __init__(self, latent_d=20):\n","        super(VAE, self).__init__()\n","\n","        self.latent_d = latent_d\n","        self.fc1 = nn.Linear(784, 400)\n","        self.fc21 = nn.Linear(400, latent_d)\n","        self.fc22 = nn.Linear(400, latent_d)\n","        self.fc3 = nn.Linear(latent_d, 400)\n","        self.fc4 = nn.Linear(400, 784)\n","\n","    def encode(self, x):\n","        h1 = F.relu(self.fc1(x))\n","        return self.fc21(h1), self.fc22(h1)\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5*logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps*std\n","\n","    def decode(self, z):\n","        h3 = F.relu(self.fc3(z))\n","        return torch.sigmoid(self.fc4(h3))\n","\n","    def forward(self, x):\n","        mu, logvar = self.encode(x.view(-1, 784))\n","        z = self.reparameterize(mu, logvar)\n","        return self.decode(z), mu, logvar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tg9D01vDJuFq"},"source":["def get_trained_vae(dataset_name,latent_d):\n","  model_path = notebook_data_path + 'trained_models/'\n","  if not os.path.exists(model_path):\n","    os.mkdir(model_path)\n","  vae_filename = model_path + dataset_name + '_vae_d' + str(latent_d) + '.pkl'\n","  if not os.path.exists(vae_filename):\n","    print('VAE does not exist. Training it now.')\n","    train_vae(dataset_name,latent_d,vae_filename)\n","  model = pickle.load(open(vae_filename, 'rb'))\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5zGwB-XOLrhT"},"source":["#@title Code: VAE training\n","\"\"\"\n","The following code is a slightly modified version of the pytorch library's\n","example directory for training a simple VAE.\n","\"\"\"\n","def train_vae(datasetname,latent_d,filename):\n","    sys.argv = ['-f']\n","\n","    parser = argparse.ArgumentParser(description='VAE MNIST Example')\n","    parser.add_argument('--batch-size', type=int, default=128, metavar='N',\n","                        help='input batch size for training (default: 128)')\n","    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n","                        help='number of epochs to train (default: 10)')\n","    parser.add_argument('--no-cuda', action='store_true', default=False,\n","                        help='disables CUDA training')\n","    parser.add_argument('--seed', type=int, default=1, metavar='S',\n","                        help='random seed (default: 1)')\n","    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n","                        help='how many batches to wait before logging training status')\n","    parser.add_argument('--vis-interval',type=int, default=10, metavar='N',\n","                        help='how many batches to wait before dumping visualization')\n","    args = parser.parse_args()\n","    args.cuda = not args.no_cuda and torch.cuda.is_available()\n","\n","    # torch.manual_seed(args.seed)\n","\n","    kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n","\n","\n","    dataset_name = datasetname\n","    if dataset_name == 'mnist':\n","        traindataset = datasets.MNIST(notebook_data_path + 'data/', train=True, download=True,\n","                      transform=transforms.ToTensor())\n","\n","        testdataset = datasets.MNIST(notebook_data_path + 'data/', train=False, transform=transforms.ToTensor())\n","\n","    elif dataset_name in ['angle', 'circleangle']:\n","        transformlist = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n","                                        transforms.ToTensor()])\n","        traindataset = datasets.ImageFolder('./data/' + dataset_name + '/', transform=transformlist)\n","        testdataset = datasets.ImageFolder('./data/' + dataset_name + '/', transform=transformlist)\n","\n","    elif dataset_name == 'untrained':\n","        args.epochs = 0\n","        # dummy code\n","        traindataset = datasets.MNIST(notebook_data_path + 'data/', train=True, download=True,\n","              transform=transforms.ToTensor())\n","\n","        testdataset = datasets.MNIST(notebook_data_path + 'data/', train=False, transform=transforms.ToTensor())\n","\n","\n","    train_loader = torch.utils.data.DataLoader(traindataset,\n","        batch_size=args.batch_size, shuffle=True, **kwargs)\n","    test_loader = torch.utils.data.DataLoader(testdataset,\n","        batch_size=args.batch_size, shuffle=True, **kwargs)\n","\n","    # Reconstruction + KL divergence losses summed over all elements and batch\n","    def vae_loss_function(recon_x, x, mu, logvar):\n","        BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n","\n","        # see Appendix B from VAE paper:\n","        # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n","        # https://arxiv.org/abs/1312.6114\n","        # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n","        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","\n","        return BCE + KLD\n","\n","    def vae_train(model, optimizer, epoch):\n","        model.train()\n","        train_loss = 0\n","        for batch_idx, (data, _) in enumerate(train_loader):\n","            data = data.to(device)\n","            optimizer.zero_grad()\n","            recon_batch, mu, logvar = model(data)\n","            loss = vae_loss_function(recon_batch, data, mu, logvar)\n","            loss.backward()\n","            train_loss += loss.item()\n","            optimizer.step()\n","            if batch_idx % args.log_interval == 0:\n","                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                    epoch, batch_idx * len(data), len(train_loader.dataset),\n","                    100. * batch_idx / len(train_loader),\n","                    loss.item() / len(data)))\n","            # if batch_idx % args.vis_interval == 0:\n","                # vis_weights(model)\n","\n","        print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n","\n","    model = VAE(latent_d = latent_d).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","    for epoch in range(1, args.epochs + 1):\n","        vae_train(model, optimizer, epoch)\n","    pickle.dump(model, open(filename, 'wb'))\n","    print('trained',latent_d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KLfpTUGRErMU"},"source":["\"\"\"\n","Train VAE on MNIST dataset with latent dimension 5.\n","The first time that you do this, the model will save the model to your Google\n","Drive to allow for re-use later on.\n","\"\"\"\n","model = get_trained_vae('mnist', 5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ANWBDXhL_WDA"},"source":["# Computing geodesics on manifolds\n","\n","Implementation of the \"classic\" approach where you start with straight-line interpolation in latent space and perturb it to obtain shorter a path."]},{"cell_type":"code","metadata":{"id":"chXS4CY6YqDS"},"source":["import torch.nn.functional as F\n","import torch.optim as optim\n","\n","def minimize_path_energy(model, z0, z1, numpts=10,numtrainiter=1000,learning_rate=0.001,verbose=False):\n","  \"\"\"\n","  Initialization: a linear interpolating path between z0 and z1 with numpts number of points.\n","  Output: a path with numpts between z0 and z1 trained to minimize energy with respect to the model.\n","  \"\"\"\n","\n","  # Initialize the interpolation between z0 and z1 with a linear interpolation.\n","  t = torch.linspace(1 / (numpts + 1), numpts / (numpts + 1), numpts).to(device)\n","  interp_points = torch.outer(1 - t, torch.flatten(z0)) + torch.outer(t, torch.flatten(z1))\n","  interp_points.requires_grad = True\n","\n","  # For convenience, precompute x0 and x1.\n","  x0 = model.decode(z0).detach()\n","  x1 = model.decode(z1).detach()\n","\n","  optimizer = optim.Adam([interp_points], lr=learning_rate)\n","  for i in range(numtrainiter):\n","    imgs = model.decode(interp_points)\n","\n","    # compute the energy of the path\n","    loss = torch.sum((torch.cat((x0, imgs)) - torch.cat((imgs, x1)))**2)\n","\n","    # # compute the length of the path\n","    # loss = torch.sqrt(torch.sum((torch.cat((x0, imgs)) - torch.cat((imgs, x1)))**2))\n","\n","    if verbose:\n","      with torch.no_grad():\n","        if i % 1000 == 0:\n","          print('loss',i,loss.to('cpu'))\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","  imgs = model.decode(interp_points)\n","\n","  # compute the energy of the path\n","  loss = torch.sum((torch.cat((x0, imgs)) - torch.cat((imgs, x1)))**2)\n","\n","  # # compute the length of the path\n","  # loss = torch.sqrt(torch.sum((torch.cat((x0, imgs)) - torch.cat((imgs, x1)))**2))\n","\n","  return torch.cat((z0, interp_points.detach(), z1)), loss.detach()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fzh830szO8tC"},"source":["def get_curve_length(model, zseq):\n","  length = 0\n","  for i in range(zseq.shape[0]-1):\n","    length = length + torch.sqrt(torch.sum((model.decode(zseq[i,:]) - model.decode(zseq[i+1,:])) ** 2))\n","  return length"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pZq3o_25rRtW"},"source":["def disp_vec_img(a,filename=None):\n","  with torch.no_grad():\n","    a = np.asarray(a.to('cpu'))\n","    pixels = a.reshape((28, 28))\n","    plt.imshow(pixels, cmap='gray')\n","    if filename is None:\n","      plt.show()\n","    else:\n","      plt.savefig(filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0x7RYA_G3i0G"},"source":["import imageio\n","from base64 import b64encode\n","from IPython.display import HTML\n","\n","def display_imageseq_video(zseq, video_file='test.mp4'):\n","  with torch.no_grad():\n","    imageseq = model.decode(zseq)\n","    imageseq = (imageseq * 255).byte()\n","  imageseq = np.asarray(imageseq.to('cpu'))\n","  imageseq = [np.pad(imageseq[i,:].reshape((28,28)),((2,2),(2,2))) for i in range(imageseq.shape[0])]\n","  imageio.mimwrite('test.mp4', imageseq, ffmpeg_params=['-sws_flags', 'neighbor', '-vf', 'scale=320:320'], fps=200); \n","  mp4 = open('test.mp4','rb').read()\n","  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n","  htmlobj = HTML(\"\"\"\n","  <video width=320 controls>\n","        <source src=\"%s\" type=\"video/mp4\">\n","  </video>\n","  \"\"\" % data_url)\n","  return htmlobj"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EChSI0o6KWK"},"source":["z0 = torch.randn([1, model.latent_d]).to(device)\n","z1 = torch.randn([1, model.latent_d]).to(device)\n","print('We will be interpolating between the following two random digits:')\n","disp_vec_img(model.decode(z0))\n","disp_vec_img(model.decode(z1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Ga_9seq6FLy"},"source":["numpts = 1000\n","zlinearseq, _ = minimize_path_energy(model, z0, z1, numpts=numpts,numtrainiter=0)\n","zseq, _ = minimize_path_energy(model, z0, z1, numpts=numpts,numtrainiter=3001,learning_rate=0.0005,verbose=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J4Yk_p80PSG9"},"source":["get_curve_length(model, zlinearseq)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8D6t42dCPXRt"},"source":["get_curve_length(model, zseq)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wf8RerMUnF4b"},"source":["def component_orth_to(vec, subspace):\n","  vec2 = torch.clone(vec)\n","  sub2 = torch.clone(subspace)\n","  # gram-schmidt orthogonalization of sub2\n","  for i in range(0,sub2.shape[0]):\n","    for j in range(i):\n","      sub2[i,:] = sub2[i,:] - sub2[j,:] * torch.dot(sub2[j,:], sub2[i,:])\n","    sub2[i,:] = sub2[i,:] / torch.norm(sub2[i,:])\n","  # print(sub2)\n","  \n","  for i in range(vec.shape[0]):\n","    for j in range(0,sub2.shape[0]):\n","      vec2[i,:] = vec2[i,:] - sub2[j,:] * torch.dot(sub2[j,:],vec2[i,:])\n","\n","  return vec2\n","\n","\n","orth_to_1d = component_orth_to(zseq - z0, z1 - z0)\n","orth_to_2d = component_orth_to(zseq - z0, torch.cat((z0,z1)))\n","# print(torch.norm(ans[0,:]))\n","# print(torch.norm(ans[1,:]))\n","# print(torch.dot(ans[0,:],ans[1,:]))\n","print(torch.norm(zseq,dim=1))\n","print(torch.norm(orth_to_1d,dim=1))\n","print(torch.norm(orth_to_2d,dim=1))\n","plt.plot(np.asarray((torch.norm(orth_to_1d,dim=1) / torch.norm(orth_to_2d,dim=1)).detach().cpu()))\n","\n","# The takeaway of this code block when run on the untrained network\n","# is that projection of zseq to (z0,z1) plane is roughly\n","# the same as projection to z0 -> z1 line. This indicates that any deviations\n","# from the straight line interpolation are not due to \"curvature of the manifold\",\n","# but rather to \"noise\" effects."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nUTaOJKzmn4a"},"source":["zseq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fc6YNa-WmtJK"},"source":["display_imageseq_video(zlinearseq,video_file='test1.mp4')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLQJDojW38JV"},"source":["display_imageseq_video(zseq,'test2.mp4')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aPxilmUDGG8E"},"source":["# Geodesics restricted to the straight line\n","\n","In this section, we optimize over geodesics restricted to the straight line. Obviously, the only improvement over the original geodesic is due to the spacing of the points on the straight line improving.\n","\n","This can be computed in two ways:\n","\n","(1) We can take the arc length of the straight line (computed using Euler integration), and derive the optimal energy of an interpolation from it.\n","\n","(2) We can optimize with Adam.\n","\n","Naturally, I will implement and compare both approaches."]},{"cell_type":"code","metadata":{"id":"W1rtHNVLGrO8"},"source":["import torch.nn.functional as F\n","import torch.optim as optim\n","\n","def minimize_straight_line_energy(model, z0, z1, numpts=10,numtrainiter=1000,learning_rate=0.001,verbose=False):\n","  \"\"\"\n","  Initialization: a linear interpolating path between z0 and z1 with numpts number of points.\n","  Output: a path with numpts between z0 and z1 trained to minimize energy with respect to the model.\n","  \"\"\"\n","\n","  # Initialize the interpolation between z0 and z1 with a linear interpolation.\n","  t = torch.linspace(1 / (numpts + 1), numpts / (numpts + 1), numpts).to(device)\n","  t.requires_grad = True\n","\n","  # For convenience, precompute x0 and x1.\n","  x0 = model.decode(z0).detach()\n","  x1 = model.decode(z1).detach()\n","\n","  optimizer = optim.Adam([t], lr=learning_rate)\n","  for i in range(numtrainiter):\n","    interp_points = torch.outer(1 - t, torch.flatten(z0)) + torch.outer(t, torch.flatten(z1))\n","    imgs = model.decode(interp_points)\n","\n","    # compute the energy of the path\n","    loss = torch.sum((torch.cat((x0, imgs)) - torch.cat((imgs, x1)))**2)\n","\n","    if verbose:\n","      with torch.no_grad():\n","        if i % 1000 == 0:\n","          print('loss',i,loss.to('cpu'))\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","  interp_points = torch.outer(1 - t, torch.flatten(z0)) + torch.outer(t, torch.flatten(z1))\n","  imgs = model.decode(interp_points)\n","  loss = torch.sum((torch.cat((x0, imgs)) - torch.cat((imgs, x1)))**2)\n","  return torch.cat((z0, interp_points.detach(), z1)), loss.detach()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m8aDSFVNghvp"},"source":["numtrials = 1\n","dist_parameter = 4\n","diff = torch.randn([numtrials, model.latent_d]).to(device) * math.sqrt(2)\n","diff = diff / torch.norm(diff,dim=1).view((numtrials,1)) * dist_parameter\n","z0 = torch.randn([numtrials, model.latent_d]).to(device) * math.sqrt(1/2) + diff / 2\n","z1 = z0 + diff"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D9TBIX_qQMZ2"},"source":["z0 = torch.randn([1, model.latent_d]).to(device)\n","z1 = torch.randn([1, model.latent_d]).to(device)\n","print('We will be interpolating between the following two random digits:')\n","disp_vec_img(model.decode(z0))\n","disp_vec_img(model.decode(z1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NNxiDkq_HW-G"},"source":["numpts = 1000\n","znaiveseq, naiveenergy = minimize_path_energy(model, z0, z1, numpts=numpts,numtrainiter=0)\n","zstraightseq, straightenergy = minimize_straight_line_energy(model, z0, z1, numpts=numpts,numtrainiter=10000,learning_rate=0.0005,verbose=True)\n","zseq, pathenergy = minimize_path_energy(model, z0, z1, numpts=numpts,numtrainiter=10000,learning_rate=0.0005,verbose=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6J_Q-2qVQTlW"},"source":["print(get_curve_length(model,znaiveseq))\n","print(get_curve_length(model,zstraightseq))\n","print(get_curve_length(model,zseq))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zgj0uCG4RPXY"},"source":["model = get_trained_vae('untrained',5)\n","\n","naive_lengths = []\n","straight_lengths = []\n","optimized_lengths = []\n","numtrials = 1\n","\n","for trial_num in range(numtrials):\n","  z0 = torch.randn([1, model.latent_d]).to(device)\n","  z1 = torch.randn([1, model.latent_d]).to(device)\n","\n","  # dist_parameter = 100\n","  # diff = torch.randn([1, model.latent_d]).to(device) * math.sqrt(2)\n","  # diff = diff / torch.norm(diff,dim=1).view((1,1)) * dist_parameter\n","  # z0 = torch.randn([1, model.latent_d]).to(device) * math.sqrt(1/2) + diff / 2\n","  # z1 = z0 + diff\n","\n","  # print('We will be interpolating between the following two random digits:')\n","  # disp_vec_img(model.decode(z0))\n","  # disp_vec_img(model.decode(z1))\n","  print('trial',trial_num)\n","  numpts = 20\n","  znaiveseq, naiveenergy = minimize_path_energy(model, z0, z1, numpts=numpts,numtrainiter=0)\n","  # zstraightseq, straightenergy = minimize_straight_line_energy(model, z0, z1, numpts=numpts,numtrainiter=3001,learning_rate=0.0005,verbose=True)\n","  zseq, pathenergy = minimize_path_energy(model, z0, z1, numpts=numpts,numtrainiter=10001,learning_rate=0.0005,verbose=True)\n","\n","  with torch.no_grad():\n","    naive_lengths.append(get_curve_length(model,znaiveseq).cpu())\n","    # straight_lengths.append(get_curve_length(model,zstraightseq).cpu())\n","    optimized_lengths.append(get_curve_length(model,zseq).cpu())\n","\n","naive_lengths = np.asarray(naive_lengths)\n","# straight_lengths = np.asarray(straight_lengths)\n","optimized_lengths = np.asarray(optimized_lengths)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x43FcJJiSTnZ"},"source":["plt.scatter(np.linspace(0,25,100),np.linspace(0,25,100))\n","plt.scatter(np.asarray(naive_lengths), np.asarray(optimized_lengths))\n","# plt.scatter(np.asarray(naive_lengths), np.asarray(straight_lengths))\n","plt.show()\n","plt.scatter(np.asarray(naive_lengths),np.asarray(optimized_lengths) / np.asarray(naive_lengths))\n","plt.show()\n","# straight_lengths - naive_lengths"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mwEe8Ws_RzMk"},"source":["np.asarray([x.cpu() for x in optimized_lengths])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rRRL2vR_RqvO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8c_2JZ9XpsfJ"},"source":["zseq = minimize_path_energy(model, z0, z1, numpts=numpts,numtrainiter=100000,learning_rate=0.0005,verbose=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cTuSpTmUrvJM"},"source":["Below, we implement the other method, which is a simple analytical calculation based on the arc-length [TODO]"]},{"cell_type":"markdown","metadata":{"id":"XjOxFlSssBKy"},"source":["# Directions of derivatives\n","\n","Although the geodesics are not straight lines in the latent space, they are pretty close! Why could this be?\n","\n","#### Hypothesis:\n","For any $z_0,z_1$ in the latent space, we have $\\frac{\\partial (g(z) - g(z_1))^2}{\\partial z}|_{z = z_0} \\approx z_1 - z_0$, where $\\approx$ means that the directions are roughly aligned. This would be the case if, for example, $g$ were a linear model. The hypothesis says that, to first-order approximation, the neural network is a linear model.\n","\n","#### Takeaway:\n","The hypothesis is roughly correct, although a little less so if z0,z1 are far apart or if the dimension is large. See below."]},{"cell_type":"code","metadata":{"id":"9nll22xOr4Z_"},"source":["import torch.nn.functional as F\n","import torch.optim as optim\n","\n","def grad_gz0_to_gz1(model, z0, z1):\n","  \"\"\"\n","  Given z0, z1, find the direction of the gradient at z0 that moves g(z0) to g(z1)\n","  \"\"\"\n","  z0.requires_grad = True\n","  x0 = model.decode(z0)\n","  x1 = model.decode(z1).detach()\n","\n","  loss = torch.sum((x0 - x1)**2)\n","  loss.backward()\n","  \n","  return z0.grad"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQ6AI_9JvpOx"},"source":["import math\n","for latent_d in [100]:\n","  for dist_parameter in [None, 0.5, 2, 4, 8, 16]:\n","    model = get_trained_vae('untrained',latent_d)\n","\n","    numtrials = 10000\n","\n","    if dist_parameter is None:\n","      z0 = torch.randn([numtrials, model.latent_d]).to(device)\n","      z1 = torch.randn([numtrials, model.latent_d]).to(device)\n","\n","    else:\n","      diff = torch.randn([numtrials, model.latent_d]).to(device) * math.sqrt(2)\n","      diff = diff / torch.norm(diff,dim=1).view((numtrials,1)) * dist_parameter\n","      z0 = torch.randn([numtrials, model.latent_d]).to(device) * math.sqrt(1/2) + diff / 2\n","      z1 = z0 + diff\n","\n","    z0grad = grad_gz0_to_gz1(model, z0, z1)\n","    z0delta = z1 - z0\n","    sample_distance = torch.norm(z0delta,dim=1).detach().cpu()\n","\n","    z0grad = z0grad / torch.norm(z0grad,dim=1).view((numtrials,1))\n","\n","    z0delta = z0delta / torch.norm(z0delta,dim=1).view((numtrials,1))\n","\n","    grad_delta_alignment = torch.sum(z0grad * z0delta, dim=1).detach().cpu()\n","    plt.hist(grad_delta_alignment,bins=20)\n","    plt.title('Dot product of grad with linear interpolation direction. latent_d =' + str(latent_d) )\n","    plt.show()\n","\n","    plt.scatter(sample_distance, grad_delta_alignment,marker='.')\n","    plt.xlabel('Distance of z0 to z1')\n","    plt.ylabel('Alignment of v = z1 - z0 vs. w = direction of gradient')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uTavzcKaTS_y"},"source":["# Greedy geodesic (start at z0 and follow the gradient so that g(z0) reaches g(z1))\n","\n","The takeaway that I got from my limited experiments here is that straight-line interpolation is better than the path found by the greedy geodesic algorithm.\n","\n","However, I only ran two trials, with d = 5, so this should be taken with a grain of salt.\n","\n","Also, this code is not very well written since I was jumping around, so it will not run if executed in a straight line."]},{"cell_type":"code","metadata":{"id":"C5_r0daSTxdN"},"source":["for latent_d in [5]:\n","  numtrials = 1\n","  numsteps = 10000\n","  step_size = 0.001\n","  z0 = torch.randn([numtrials, model.latent_d]).to(device)\n","  z1 = torch.randn([numtrials, model.latent_d]).to(device)\n","\n","  ptlist = []\n","  currz = torch.clone(z0)\n","\n","  currz.requires_grad = True\n","  x1 = model.decode(z1).detach()\n","  optimizer = optim.Adam([currz], lr=0.0001)\n","  for step in range(numsteps):\n","    ptlist.append(torch.clone(currz))\n","    currx = model.decode(currz)\n","    loss = torch.sum((currx - x1)**2)\n","    print(loss)\n","    if loss < 0.02:\n","      break\n","\n","    loss.backward()\n","    # print(torch.norm(currz.grad,dim=1))\n","    # print(currz.grad)\n","    with torch.no_grad():\n","      graddir = currz.grad / torch.norm(currz.grad, dim=1).view(numtrials, 1)\n","      currz.add_(-graddir, alpha=step_size)\n","\n","      # print(graddir)\n","\n","    optimizer.zero_grad()\n","\n","    # z0grad = z0grad / torch.norm(z0grad,dim=1).view((numtrials,1))\n","    # print(currz)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oFfjyTufagQQ"},"source":["ptlist"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3sIRb8VRT22i"},"source":["import torch.nn.functional as F\n","import torch.optim as optim\n","\n","def minimize_path_energy(model, z0, z1, init_path=None, numpts=10,numtrainiter=1000,learning_rate=0.001,verbose=False):\n","  \"\"\"\n","  Initialization: a linear interpolating path between z0 and z1 with numpts number of points.\n","  Output: a path with numpts between z0 and z1 trained to minimize energy with respect to the model.\n","  \"\"\"\n","\n","  if init_path is None:\n","    # Initialize the interpolation between z0 and z1 with a linear interpolation.\n","    t = torch.linspace(1 / (numpts + 1), numpts / (numpts + 1), numpts).to(device)\n","    interp_points = torch.outer(1 - t, torch.flatten(z0)) + torch.outer(t, torch.flatten(z1))\n","  else:\n","    interp_points = init_path\n","  interp_points.requires_grad = True\n","\n","  # For convenience, precompute x0 and x1.\n","  x0 = model.decode(z0).detach()\n","  x1 = model.decode(z1).detach()\n","\n","  optimizer = optim.Adam([interp_points], lr=learning_rate)\n","  for i in range(numtrainiter):\n","    imgs = model.decode(interp_points)\n","\n","    # compute the energy of the path\n","    loss = torch.sum((torch.cat((x0, imgs)) - torch.cat((imgs, x1)))**2)\n","\n","    if verbose:\n","      with torch.no_grad():\n","        if i % 1000 == 0:\n","          print('loss',i,loss.to('cpu'))\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","  imgs = model.decode(interp_points)\n","  loss = torch.sum((torch.cat((x0, imgs)) - torch.cat((imgs, x1)))**2)\n","  return torch.cat((z0, interp_points.detach(), z1)), loss.detach()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iG5VSnIWbAE_"},"source":["path, loss = minimize_path_energy(model,z0,z1,numpts=4852,numtrainiter=10000,learning_rate=0.0001,verbose=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iMK0IwOKdInb"},"source":["compute_path_length(model, path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZ0rvzH2cVtb"},"source":["def compute_path_length(model,path):\n","  l = 0\n","  for i in range(path.shape[0]-1):\n","    xip1 = model.decode(path[i+1,:])\n","    xi = model.decode(path[i,:])\n","    l += torch.norm(xip1 - xi)\n","  return l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HXSzo1NBeKXd"},"source":["len(ptlist)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"75zNFCRtcyZm"},"source":["compute_path_length(model,torch.cat(ptlist).detach())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"od9KorF_bN7B"},"source":["minimize_path_energy(model,z0,z1,init_path=torch.cat(ptlist).detach(), numpts=numsteps,numtrainiter=20000,verbose=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xHXngPyYfzTq"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZHeHI11wZc_j"},"source":["# Deprecated code: Geodesics of networks at initialization using analytic formula.\n","\n","This runs into some errors in the calculation of the derivative of the arccosine, and the analytic formula does not account for the random biases. I found it better to simply use the 'untrained' network instead.\n","\n"]},{"cell_type":"code","metadata":{"id":"sNSqEqSpZgS1","cellView":"form"},"source":["#@title Deprecated code: analytic distance calculation\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","def get_pairwise_energy_random_net(z1,z2,L):\n","  norm1 = torch.sum(torch.square(z1))\n","  norm2 = torch.sum(torch.square(z2))\n","  dotprod = torch.sum(z1 * z2)\n","\n","  normprod = torch.sqrt(norm1 * norm2)\n","  latentangle = torch.acos(dotprod / normprod)\n","\n","  currangle = latentangle\n","  for i in range(L):\n","    currangle = torch.acos(((np.pi - currangle) * torch.cos(currangle) + torch.sin(currangle))/np.pi)\n","  cosgenangle = torch.cos(currangle)\n","  # cosgenangle = ((np.pi - latentangle) * torch.cos(latentangle) + torch.sin(latentangle))/np.pi\n","  # cosgenangle = torch.cos(latentangle)\n","\n","  energy = norm1 + norm2 - 2 * normprod * cosgenangle\n","\n","  return energy\n","  # print(energy)\n","  # length = torch.sqrt(energy)\n","  # length = energy ** (1/2)\n","  # print('Returning length')\n","  # # print(length)\n","  # # print(norm1, norm2, dotprod)\n","  # # print(energy)\n","  # # return torch.sqrt(energy)\n","  # return length"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lXyEu4uwXEIW","cellView":"form"},"source":["#@title Deprecated code: minimize path energy random net\n","\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","def minimize_path_energy_random_net(z0, z1, L, numpts=10,numtrainiter=1000,learning_rate=0.001,verbose=False):\n","  \"\"\"\n","  Initialization: a linear interpolating path between z0 and z1 with numpts number of points.\n","  Output: a path with numpts between z0 and z1 trained to minimize energy with respect to the model.\n","  \"\"\"\n","\n","  # Initialize the interpolation between z0 and z1 with a linear interpolation.\n","  t = torch.linspace(1 / (numpts + 1), numpts / (numpts + 1), numpts).to(device)\n","  interp_points = torch.outer(1 - t, torch.flatten(z0)) + torch.outer(t, torch.flatten(z1))\n","  # interp_points = torch.rand_like(z0)\n","  interp_points.requires_grad = True\n","\n","  def totloss(interp_points):\n","    # compute the energy of the path\n","    loss = get_pairwise_energy_random_net(z0,interp_points[0,:],L)\n","    for i in range(numpts-1):\n","      loss += get_pairwise_energy_random_net(interp_points[i,:],interp_points[i+1,:],L)\n","    loss += get_pairwise_energy_random_net(interp_points[numpts-1,:],z1,L)\n","    return loss\n","\n","  optimizer = optim.Adam([interp_points], lr=learning_rate)\n","  for i in range(numtrainiter):\n","    imgs = model.decode(interp_points)\n","\n","    loss = totloss(interp_points)\n","\n","    # print(loss)\n","\n","\n","    if verbose:\n","      with torch.no_grad():\n","        if i % 100 == 0:\n","          print('loss',i,loss.to('cpu'))\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","  loss = totloss(interp_points)\n","  return torch.cat((z0, interp_points.detach(), z1)), loss.detach()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9qPJ1QU7ZgS2","cellView":"form"},"source":["#@title Deprecated: optimize paths using analytic distance for random net\n","\n","import math\n","for latent_d in [5]:\n","  # for dist_parameter in [None, 0.5, 2, 4, 8, 16]:\n","  for dist_parameter in [None]:\n","    model = get_trained_vae('mnist',latent_d)\n","\n","    numtrials = 1\n","    assert(numtrials == 1)\n","\n","    if dist_parameter is None:\n","      z0 = torch.randn([numtrials, model.latent_d]).to(device)\n","      z1 = torch.randn([numtrials, model.latent_d]).to(device)\n","\n","    else:\n","      diff = torch.randn([numtrials, model.latent_d]).to(device) * math.sqrt(2)\n","      diff = diff / torch.norm(diff,dim=1).view((numtrials,1)) * dist_parameter\n","      z0 = torch.randn([numtrials, model.latent_d]).to(device) * math.sqrt(1/2) + diff / 2\n","      z1 = z0 + diff\n","\n","    print(get_pairwise_energy_random_net(z0,z1,L=2))\n","    torch.autograd.set_detect_anomaly(True)\n","    outputs = minimize_path_energy_random_net(z0,z1,L=1,numpts=10,learning_rate=0.01,verbose=True)\n","    print(outputs)\n","\n","    # z0grad = grad_gz0_to_gz1(model, z0, z1)\n","    # z0delta = z1 - z0\n","    # sample_distance = torch.norm(z0delta,dim=1).detach().cpu()\n","\n","    # z0grad = z0grad / torch.norm(z0grad,dim=1).view((numtrials,1))\n","\n","    # z0delta = z0delta / torch.norm(z0delta,dim=1).view((numtrials,1))\n","\n","    # grad_delta_alignment = torch.sum(z0grad * z0delta, dim=1).detach().cpu()\n","    # plt.hist(grad_delta_alignment,bins=20)\n","    # plt.title('Dot product of grad with linear interpolation direction. latent_d =' + str(latent_d) )\n","    # plt.show()\n","\n","    # plt.scatter(sample_distance, grad_delta_alignment,marker='.')\n","    # plt.xlabel('Distance of z0 to z1')\n","    # plt.ylabel('Alignment of v = z1 - z0 vs. w = direction of gradient')\n","    # plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nBOfwfXLVPEX"},"source":["# George Stepaniants Code: Computing Jacobian Statistics at Sample Points on Manifold\n","model_example = get_trained_vae('untrained', 20)\n","\n","trials = 1000\n","conds = []\n","lmaxs = []\n","lmins = []\n","for i in range(trials):\n","  print(i)\n","  z = torch.randn([model_example.latent_d]).to(device)\n","  Jg = torch.autograd.functional.jacobian(model_example.decode, z)\n","  G = torch.matmul(Jg.t(), Jg)\n","\n","  cond = torch.linalg.cond(G).item()\n","  lmax = torch.lobpcg(G)[0].item()\n","  lmin = torch.lobpcg(G, largest=False)[0].item()\n","\n","  conds.append(cond)\n","  lmaxs.append(lmax)\n","  lmins.append(lmin)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VAtDTGV0W4zd"},"source":["plt.figure(1)\n","plt.title('Condition Number of Jg^T * Jg')\n","plt.hist(conds, bins=30, density=True)\n","\n","plt.figure(2)\n","plt.title('Maximum Eigenvalue of Jg^T * Jg')\n","plt.hist(lmaxs, bins=30, density=True)\n","\n","plt.figure(3)\n","plt.title('Minimum Eigenvalue of Jg^T * Jg')\n","plt.hist(lmins, bins=30, density=True)\n","\n","plt.figure(4)\n","plt.title('Minimum vs. Maximum Eigenvalues')\n","plt.scatter(lmins, lmaxs)\n","lims = [np.min([plt.xlim(), plt.ylim()]), np.max([plt.xlim(), plt.ylim()])]\n","plt.plot(lims, lims, 'r-', alpha=0.75, zorder=0)\n","plt.xlabel('Minimum Eigenvalue')\n","plt.ylabel('Maximum Eigenvalue')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"37-HpwbtDd75"},"source":["print(np.mean(conds))\n","import statistics\n","print(statistics.median(conds))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lafZ0_G4ES-6"},"source":[""],"execution_count":null,"outputs":[]}]}